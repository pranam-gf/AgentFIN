# === OpenAI API ===
OPENAI_API_KEY=
# Model for embeddings (e.g., text-embedding-ada-002, text-embedding-3-small)
EMBEDDING_MODEL_NAME=text-embedding-ada-002
EMBEDDING_MODEL_PROVIDER=openai
EMBEDDING_DIMENSION=1536

# === Pinecone Vector DB ===
PINECONE_API_KEY=
PINECONE_ENVIRONMENT=us-east-1-gcp
PINECONE_INDEX_NAME=your-cfa-index
PINECONE_CREATE_INDEX=True
PINECONE_CLOUD=aws
PINECONE_REGION=us-east-1

# === Retrieval Pipeline ===
SEARCH_TOP_K=10
USE_QUERY_EXPANSION=false
QUERY_EXPANSION_PROVIDER=openai
QUERY_EXPANSION_MODEL=gpt-3.5-turbo
USE_RERANKING=false
RERANKER_MODEL_NAME=cross-encoder/ms-marco-MiniLM-L-6-v2
RERANK_TOP_N=5

# === Generation Pipeline ===
GENERATOR_LLM_PROVIDER=openai
GENERATOR_LLM_MODEL=gpt-3.5-turbo
SYSTEM_PROMPT="You are a helpful assistant specialized in CFA Level 3 exam preparation. Answer the question based on the provided context. If the answer is not in the context, say 'I don't have enough information to answer that question."
MAX_CONTEXT_LENGTH=4000
MAX_TOKENS_PER_CHUNK=1000

# === Chunking ===
CHUNK_SIZE=1000
CHUNK_OVERLAP=100

# === Other (Optional) ===
# Add any additional provider/model keys as needed